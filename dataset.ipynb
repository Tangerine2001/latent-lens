{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['secret'])\n",
      "21919\n",
      "21919\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import openai\n",
    "\n",
    "with open('keys.json', \"r\") as f:\n",
    "    keys = json.load(f)\n",
    "print(keys.keys())\n",
    "\n",
    "openai.api_key = keys['secret']\n",
    "\n",
    "dataDir = \"datasets/\"\n",
    "with open(dataDir + \"counterfact.json\", \"r\") as f:\n",
    "    counterfact = json.load(f)\n",
    "if os.path.exists(dataDir + \"related.json\"):\n",
    "    with open(dataDir +\"related.json\", \"r\") as f:\n",
    "        related = json.load(f)\n",
    "else:\n",
    "    related = []\n",
    "print(len(counterfact))\n",
    "print(len(related))\n",
    "totalTokens = 0\n",
    "\n",
    "def costEstimate(tokens):\n",
    "    return (tokens/1000) * 0.002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genMsg(idx):\n",
    "    msg = counterfact[idx]['requested_rewrite']['prompt']\n",
    "    msg = msg.replace(\"{}\", counterfact[idx]['requested_rewrite']['subject'])\n",
    "    msg = msg + \" \" + counterfact[idx]['requested_rewrite']['target_true'][\"str\"] + \".\"\n",
    "    msg = msg + f\" Can you write a list on one line without commas of related words to the subject of the first sentence, {counterfact[idx]['requested_rewrite']['subject']}.\"\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genResponse(msg):\n",
    "    global totalTokens\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": msg}\n",
    "        ],\n",
    "        max_tokens=20,\n",
    "        # stop=[\"\\n\", \".\"],\n",
    "        temperature=0.8,\n",
    "        presence_penalty=0.0,\n",
    "    )\n",
    "    totalTokens += response[\"usage\"][\"total_tokens\"]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [\".\", \",\", \"!\", \"?\", \";\", \":\", \"-\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\"]\n",
    "def postProcess(words):\n",
    "    for punc in punctuation:\n",
    "        words = words.replace(punc, \" \")\n",
    "    words = words.split(\" \")\n",
    "    words = [word for word in words if word != \"\"]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Michael Einhorn\\Documents\\MLProjects\\latent-lens\\dataset.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/dataset.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(related)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/dataset.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(counterfact[i])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/dataset.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m msg \u001b[39m=\u001b[39m genMsg(i)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/dataset.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(msg)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i = len(related)\n",
    "print(counterfact[i])\n",
    "msg = genMsg(i)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = genResponse(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "# print(postProcess(response[\"choices\"][0][\"message\"][\"content\"]))\n",
    "# print(response[\"choices\"][0][\"finish_reason\"])\n",
    "# print(response[\"usage\"][\"total_tokens\"])\n",
    "# print(costEstimate(totalTokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21918 / 21919 Current Cost 1.724052000000000235\r"
     ]
    }
   ],
   "source": [
    "testing = False\n",
    "\n",
    "for i in range(len(related), len(counterfact)):\n",
    "    msg = genMsg(i)\n",
    "    response = genResponse(msg)\n",
    "    words = postProcess(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    if testing:\n",
    "        print(msg)\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "        print(words)\n",
    "\n",
    "    entry = counterfact[i]\n",
    "    entry[\"relatedWords\"] = words\n",
    "    entry[\"responseRaw\"] = response.to_dict()\n",
    "    related.append(entry)\n",
    "    with open(dataDir + \"related.json\", \"w\") as f:\n",
    "        json.dump(related, f)\n",
    "\n",
    "    # print(response[\"choices\"][0][\"finish_reason\"])\n",
    "    print(f\"{i} / {len(counterfact)} Current Cost {costEstimate(totalTokens)}\", end=\"\\r\")\n",
    "    if costEstimate(totalTokens) > 10:\n",
    "        break\n",
    "\n",
    "    if testing:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['case_id', 'pararel_idx', 'requested_rewrite', 'paraphrase_prompts', 'neighborhood_prompts', 'attribute_prompts', 'generation_prompts', 'relatedWords', 'responseRaw'])\n",
      "['actor', 'theatre', 'film', 'stage', 'performance', 'drama', 'comedy', 'tragedy', 'audition', 'rehearsal', 'script', 'character', 'role', 'director', 'producer', 'cinematographer', 'screenplay', 'set', 'design']\n",
      "21919\n"
     ]
    }
   ],
   "source": [
    "print(related[-1].keys())\n",
    "print(related[-1][\"relatedWords\"])\n",
    "print(len(related))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import IterableDataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoConfig\n",
    "\n",
    "from core import padded_stack, stack_dicts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataDir +\"related.json\", \"r\") as f:\n",
    "    related = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json with strings to tuple of tensors\n",
    "class RelatedDataset(Dataset):\n",
    "    def __init__(self, dataJson, tokenizer):\n",
    "        self.dataJson = dataJson\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataJson)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        prompt, response, related = self.formatText(index)\n",
    "\n",
    "        promptT = self.tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].squeeze(0)\n",
    "        responseT = self.tokenizer(response, return_tensors=\"pt\")[\"input_ids\"].squeeze(0)\n",
    "        relatedT = self.tokenizer(related, return_tensors=\"pt\")[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        return promptT, responseT, relatedT\n",
    "\n",
    "    def formatText(self, idx):\n",
    "        prompt = self.dataJson[idx]['requested_rewrite']['prompt']\n",
    "        prompt = prompt.replace(\"{}\", self.dataJson[idx]['requested_rewrite']['subject'])\n",
    "        response = counterfact[idx]['requested_rewrite']['target_true'][\"str\"] + \".\"\n",
    "        related = self.dataJson[idx]['relatedWords']\n",
    "        relatedStr = related[0]\n",
    "        for r in related[1:]:\n",
    "            relatedStr += \" \" + r\n",
    "        return prompt, response, relatedStr\n",
    "    \n",
    "# batching and padding, use left pad tokkenizer\n",
    "class RelatedCollator():\n",
    "    def __init__(self, tokenizer):\n",
    "        self.textCollator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        prompt, response, related = zip(*batch)\n",
    "\n",
    "        print(prompt)\n",
    "        prompt = self.textCollator(prompt)\n",
    "        response = self.textCollator(response)\n",
    "        related = self.textCollator(related)\n",
    "\n",
    "        prompt[\"attention_mask\"] = torch.where(prompt[\"input_ids\"] == self.pad_token_id, 0, 1)\n",
    "        response[\"attention_mask\"] = torch.where(response[\"input_ids\"] == self.pad_token_id, 0, 1)\n",
    "        related[\"attention_mask\"] = torch.where(related[\"input_ids\"] == self.pad_token_id, 0, 1)\n",
    "\n",
    "        return prompt, response, related # token index in [\"input_ids\"], -100 for pad in [\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "source": [
    "# left pad so all generations start at the same index\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side='left', return_special_tokens_mask=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "print(tokenizer.pad_token_id)\n",
    "dataset = RelatedDataset(related, tokenizer)\n",
    "collator = RelatedCollator(tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collator, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([7554, 1766, 1616,  373, 4642,  287]), tensor([3351,  295,  256,   34,   11, 4635,  416]))\n",
      "dict_keys(['input_ids', 'labels', 'attention_mask'])\n",
      "tensor([[50257,  7554,  1766,  1616,   373,  4642,   287],\n",
      "        [ 3351,   295,   256,    34,    11,  4635,   416]])\n",
      "tensor([[-100, 7554, 1766, 1616,  373, 4642,  287],\n",
      "        [3351,  295,  256,   34,   11, 4635,  416]])\n",
      "tensor([[0, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[50257, 23421,    13],\n",
      "        [48236,  4265,    13]])\n",
      "tensor([[ -100, 23421,    13],\n",
      "        [48236,  4265,    13]])\n",
      "tensor([[0, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[50257, 50257, 50257, 23421,  4082,  3594, 37275,   666, 15606,  3707,\n",
      "         29396,   520,  3362,   338,  3961],\n",
      "        [48236,  4265, 15062,   431,  7092,  1097,  4930,  3420,  8880,  7825,\n",
      "          3708, 31537,  1891, 17969, 11478]])\n",
      "tensor([[ -100,  -100,  -100, 23421,  4082,  3594, 37275,   666, 15606,  3707,\n",
      "         29396,   520,  3362,   338,  3961],\n",
      "        [48236,  4265, 15062,   431,  7092,  1097,  4930,  3420,  8880,  7825,\n",
      "          3708, 31537,  1891, 17969, 11478]])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# test dataloader\n",
    "for i, batch in enumerate(dataloader):\n",
    "    print(batch[0].keys())\n",
    "    print(batch[0][\"input_ids\"])\n",
    "    print(batch[0][\"labels\"])\n",
    "    print(batch[0][\"attention_mask\"])\n",
    "    print(batch[1][\"input_ids\"])\n",
    "    print(batch[1][\"labels\"])\n",
    "    print(batch[1][\"attention_mask\"])\n",
    "    print(batch[2][\"input_ids\"])\n",
    "    print(batch[2][\"labels\"])\n",
    "    print(batch[2][\"attention_mask\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
