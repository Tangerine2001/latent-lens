{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FU-1GTZT28li"
      },
      "source": [
        "# The tuned lens ðŸ”Ž\n",
        "A tuned lens allows us to peak at the iterative computations that a transformer is using the compute the next token.\n",
        "\n",
        "A lens into a transformer with n layers allows you to replace the last $m$ layers of the model with an [affine transformation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) (we call these affine translators).\n",
        "\n",
        "This essentially skips over these last few layers and lets you see the best prediction that can be made from the model's representations, i.e. the residual stream, at layer $n - m$. Since the representations may be rotated, shifted, or stretched from layer to layer it's useful to train the len's affine translators specifically on each layer. This training is what differentiates this method from simpler approaches that decode the residual stream of the network directly using the unembeding layer i.e. the logit lens. We explain this process along with more applications of the method in [the paper](ttps://arxiv.org/abs/2303.08112).\n",
        "\n",
        "You can find the complete set of pretrained lenses on [the hugging face space](https://huggingface.co/spaces/AlignmentResearch/tuned-lens/tree/main/lens).\n",
        "\n",
        "## Usage\n",
        "Since the tuned lens produces a distribution of predictions to visualize it's output we need to we need to provide a summary statistic to plot.  The default is simply [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)), but you can also choose the [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) with the target token, or the [KL divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between the model's predictions and the tuned lens' predictions. You can also hover over a token to see more of the distribution i.e. the top 10 most probable tokens and their probabilities.\n",
        "\n",
        "## Examples\n",
        "Some interesting examples you can try.\n",
        "\n",
        "### Copy paste:\n",
        "```\n",
        "Copy: A!2j!#u&NGApS&MkkHe8Gm!#\n",
        "Paste: A!2j!#u&NGApS&MkkHe8Gm!#\n",
        "```\n",
        "\n",
        "### Trivial in-context learning\n",
        "```\n",
        "inc 1 2\n",
        "inc 4 5\n",
        "inc 13 \n",
        "```\n",
        "\n",
        "#### Addition\n",
        "```\n",
        "add 1 1 2\n",
        "add 3 4 7\n",
        "add 13 2 \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W9cRsIdK2-Jm"
      },
      "outputs": [],
      "source": [
        "# !pip install tuned-lens==0.0.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z9AhuLaDBDRN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from tuned_lens.nn.lenses import TunedLens, LogitLens\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "windows = False\n",
        "try:\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "except:\n",
        "  if os.name == 'nt':\n",
        "    windows = True\n",
        "\n",
        "bfloat16_available = torch.cuda.get_device_capability()[0] >= 8\n",
        "floatDtype = torch.bfloat16 if bfloat16_available else torch.float16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FGd2YmyD28lk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "loadLens = True\n",
        "modelName = 'EleutherAI/pythia-1b'\n",
        "LensName = \"outputs\\\\test-1b\\\\\"\n",
        "# modelName = 'sshleifer/tiny-gpt2'\n",
        "# To try a diffrent modle / lens check if the lens is avalible then modify this code\n",
        "model = AutoModelForCausalLM.from_pretrained(modelName, low_cpu_mem_usage=True, torch_dtype=floatDtype)\n",
        "model.eval()\n",
        "model.requires_grad_(False)\n",
        "model = model.to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
        "if loadLens:\n",
        "    tuned_lens = TunedLens.load(LensName, map_location=device)\n",
        "else:\n",
        "    tuned_lens = TunedLens(model)\n",
        "tuned_lens = tuned_lens.to(device)\n",
        "# logit_lens = LogitLens(model)\n",
        "logit_lens = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===========================================================================\n",
            "Layer (type:depth-idx)                             Param #\n",
            "===========================================================================\n",
            "GPTNeoXForCausalLM                                 --\n",
            "â”œâ”€GPTNeoXModel: 1-1                                --\n",
            "â”‚    â””â”€Embedding: 2-1                              (103,022,592)\n",
            "â”‚    â””â”€ModuleList: 2-2                             --\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-1                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-2                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-3                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-4                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-5                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-6                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-7                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-8                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-9                      (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-10                     (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-11                     (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-12                     (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-13                     (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-14                     (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-15                     (50,358,272)\n",
            "â”‚    â”‚    â””â”€GPTNeoXLayer: 3-16                     (50,358,272)\n",
            "â”‚    â””â”€LayerNorm: 2-3                              (4,096)\n",
            "â”œâ”€Linear: 1-2                                      (103,022,592)\n",
            "===========================================================================\n",
            "Total params: 1,011,781,632\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1,011,781,632\n",
            "===========================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "TunedLens                                --\n",
            "â”œâ”€Sequential: 1-1                        --\n",
            "â”œâ”€LayerNorm: 1-2                         (4,096)\n",
            "â”œâ”€Linear: 1-3                            (103,022,592)\n",
            "â”œâ”€Linear: 1-4                            4,196,352\n",
            "â”œâ”€ModuleList: 1-5                        --\n",
            "â”‚    â””â”€Linear: 2-1                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-2                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-3                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-4                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-5                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-6                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-7                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-8                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-9                       4,196,352\n",
            "â”‚    â””â”€Linear: 2-10                      4,196,352\n",
            "â”‚    â””â”€Linear: 2-11                      4,196,352\n",
            "â”‚    â””â”€Linear: 2-12                      4,196,352\n",
            "â”‚    â””â”€Linear: 2-13                      4,196,352\n",
            "â”‚    â””â”€Linear: 2-14                      4,196,352\n",
            "â”‚    â””â”€Linear: 2-15                      4,196,352\n",
            "=================================================================\n",
            "Total params: 170,168,320\n",
            "Trainable params: 67,141,632\n",
            "Non-trainable params: 103,026,688\n",
            "=================================================================\n"
          ]
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "print(summary(model))\n",
        "print(summary(tuned_lens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL8f4i2828lm",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc987896309f40eeae9998a57613061e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='Select Lens:', options=(('Tuned Lens', TunedLens(\n",
              "  (extra_layers)â€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tuned_lens.plotting import plot_lens, get_lens_stream\n",
        "import ipywidgets as widgets\n",
        "from plotly import graph_objects as go\n",
        "\n",
        "\n",
        "def make_plot(lens, text, layer_stride, statistic, token_range):\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "    if len(input_ids[0]) == 0:\n",
        "        return widgets.Text(\"Please enter some text.\")\n",
        "    \n",
        "    if (token_range[0] == token_range[1]):\n",
        "        return widgets.Text(\"Please provide valid token range.\")\n",
        "\n",
        "    return go.FigureWidget(\n",
        "        plot_lens(\n",
        "            model,\n",
        "            tokenizer,\n",
        "            lens,\n",
        "            layer_stride=layer_stride,\n",
        "            input_ids=input_ids,\n",
        "            start_pos=token_range[0],\n",
        "            end_pos=token_range[1] if token_range[1] > 0 else None,\n",
        "            statistic=statistic,\n",
        "        )\n",
        "    )\n",
        "\n",
        "style = {'description_width': 'initial'}\n",
        "statistic_wdg = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Entropy', 'entropy'),\n",
        "        ('Cross Entropy', 'ce'),\n",
        "        ('Forward KL', 'forward_kl'),\n",
        "    ],\n",
        "    description='Select Statistic:',\n",
        "    style=style,\n",
        ")\n",
        "text_wdg = widgets.Textarea(\n",
        "    description=\"Input Text\",\n",
        "    value=\"it was the best of times, it was the worst of times\",\n",
        ")\n",
        "lens_wdg = widgets.Dropdown(\n",
        "    options=[('Tuned Lens', tuned_lens), ('Logit Lens', logit_lens)],\n",
        "    description='Select Lens:',\n",
        "    style=style,\n",
        ")\n",
        "\n",
        "layer_stride_wdg = widgets.BoundedIntText(\n",
        "    value=2,\n",
        "    min=1,\n",
        "    max=model.config.num_hidden_layers//2,\n",
        "    step=1,\n",
        "    description='Layer Stride:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "token_range_wdg = widgets.IntRangeSlider(\n",
        "    description='Token Range',\n",
        "    min=0,\n",
        "    max=1,\n",
        "    step=1,\n",
        "    style=style,\n",
        ")\n",
        "\n",
        "\n",
        "def update_token_range(*args):\n",
        "    token_range_wdg.max = len(tokenizer.encode(text_wdg.value))\n",
        "\n",
        "update_token_range()\n",
        "\n",
        "token_range_wdg.value = [0, token_range_wdg.max]\n",
        "text_wdg.observe(update_token_range, 'value')\n",
        "\n",
        "interact = widgets.interact.options(manual_name='Run Lens', manual=True)\n",
        "\n",
        "with torch.autocast(\"cuda\", dtype=floatDtype):\n",
        "    plot = interact(\n",
        "        make_plot,\n",
        "        text=text_wdg,\n",
        "        statistic=statistic_wdg,\n",
        "        lens=lens_wdg,\n",
        "        layer_stride=layer_stride_wdg,\n",
        "        token_range=token_range_wdg,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from torch.utils.data import DataLoader\n",
        "from tuned_lens.scripts.train_loop_latent import RelatedCollator\n",
        "from tuned_lens.scripts.lens_latent import RelatedDataset\n",
        "# open related json to gain access to dataset\n",
        "dataDir = \"datasets/\"\n",
        "with open(dataDir +\"related.json\", \"r\") as f: \n",
        "    relatedJson = json.load(f)\n",
        "        \n",
        "dataset = RelatedDataset(relatedJson, tokenizer)\n",
        "collator = RelatedCollator(tokenizer, dataset.pad_to_multiple_of)\n",
        "dl = DataLoader(dataset, batch_size=1, collate_fn=collator, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7])\n",
            "torch.Size([1, 7])\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "where() received an invalid combination of arguments - got (bool, int, int), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other, *, Tensor out)\n * (Tensor condition, Number self, Tensor other)\n      didn't match because some of the arguments have invalid types: (!bool!, !int!, !int!)\n * (Tensor condition, Tensor input, Number other)\n      didn't match because some of the arguments have invalid types: (!bool!, !int!, !int!)\n * (Tensor condition, Number self, Number other)\n      didn't match because some of the arguments have invalid types: (!bool!, !int!, !int!)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Michael Einhorn\\Documents\\MLProjects\\latent-lens\\interactive.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/interactive.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m prompt, response, related \u001b[39min\u001b[39;00m dl:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/interactive.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     hidden_lps, responseOutput \u001b[39m=\u001b[39m get_lens_stream(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/interactive.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/interactive.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 tokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/interactive.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                 statistic\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mce\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/interactive.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/MLProjects/latent-lens/interactive.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(hidden_lps)\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
            "File \u001b[1;32mc:\\Users\\Michael Einhorn\\Documents\\MLProjects\\latent-lens\\tuned_lens\\scripts\\train_loop_latent.py:48\u001b[0m, in \u001b[0;36mRelatedCollator.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdel\u001b[39;00m related[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(prompt[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 48\u001b[0m prompt[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mwhere(prompt[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_token_id, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     49\u001b[0m response[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mwhere(response[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_token_id, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     50\u001b[0m related[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mwhere(related[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_token_id, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: where() received an invalid combination of arguments - got (bool, int, int), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other, *, Tensor out)\n * (Tensor condition, Number self, Tensor other)\n      didn't match because some of the arguments have invalid types: (!bool!, !int!, !int!)\n * (Tensor condition, Tensor input, Number other)\n      didn't match because some of the arguments have invalid types: (!bool!, !int!, !int!)\n * (Tensor condition, Number self, Number other)\n      didn't match because some of the arguments have invalid types: (!bool!, !int!, !int!)\n"
          ]
        }
      ],
      "source": [
        "for prompt, response, related in dl:\n",
        "\n",
        "    hidden_lps, responseOutput = get_lens_stream(\n",
        "                model,\n",
        "                tokenizer,\n",
        "                tuned_lens,\n",
        "                layer_stride=1,\n",
        "                input_ids=prompt[\"input_ids\"],\n",
        "                input_att_mask=prompt[\"attention_mask\"],\n",
        "                response_ids=response[\"input_ids\"],\n",
        "                response_att_mask=response[\"attention_mask\"],\n",
        "                related_ids=related[\"input_ids\"],\n",
        "                related_att_mask=related[\"attention_mask\"],\n",
        "                start_pos=0,\n",
        "                end_pos=None,\n",
        "                statistic=\"ce\",\n",
        "            )\n",
        "    print(hidden_lps)\n",
        "    print(responseOutput)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tuned-lens train latent gpt2 related --loss ce --token-shift 0 --output outputs/test\n",
        "# tuned-lens train latent EleutherAI/pythia-1b related --loss ce --token-shift 0 --output outputs/test-1b-long --tokens-per-step 8192 --wandb latent-lens-long\n",
        "# tuned-lens train latent EleutherAI/pythia-6.9b related --loss ce --token-shift 0 --output outputs/test --tokens-per-step 1024 --wandb latent-lens-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "ca27fca65bbd5c56c827a2643e94bc7b2b551ee6ee2fe84566f2c789012bce4f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
